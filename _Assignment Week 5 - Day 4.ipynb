{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1EJq2ym1JBDHUEkGBR97IBYhfiC_bIyeq","timestamp":1665588396450}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **MACHINE LEARNING**"],"metadata":{"id":"4oQJq6jhDwXX"}},{"cell_type":"markdown","source":["## 1. What are the differences in Anomalies for Uniform Distribution and Normal Distribution in One-Dimensional Data?"],"metadata":{"id":"nKIkFGo-Dyw0"}},{"cell_type":"markdown","source":["When data is distributed uniformly over a finite range, the mean and standard deviation merely characterize the range of values.\n","One possible indication of anomalous behavior could be that a small neighborhood contains substantially fewer or more data points than expected from a uniform distribution.\n","\n","A normal distribution follows the empirical rule, which states that 68%, 95%, and 99.7% of the values lie within one, two, and three standard deviations of the mean, respectively.\n","About 0.1% of the points are more than 3 \\sigma3σ (three standard deviations) away from the mean, and only about 5 \\times 10^{-8}5×10 \n","−8\n"," % of the points are more than six standard deviations away from the mean.\n","Hence, a threshold (such as 3 \\times \\sigma3×σ) is chosen, and points beyond that distance from the mean are declared to be anomalous."],"metadata":{"id":"nJu45eyOENbJ"}},{"cell_type":"markdown","source":["## 2. a. What are the Swamping and Masking problems in Anomaly Detection? \n","\n","## b. What is the Change Detection problem in Anomaly Detection? "],"metadata":{"id":"j4t9CCnRbb_2"}},{"cell_type":"markdown","source":["a)Anomalies are the rare events, and this makes it very difficult to label these with high accuracy. Swamping is the phenomenon of labelling normal events as anomalies.\n","\n","When clustering algorithms are used, the data points belonging to different clusters gets merged into one cluster, if the number of segments (including outlier segments) in the dataset is not known. This causes the outlier cluster merged to a cluster with normal data points. Basically, the outliers are not detected. This is called Masking. Swamping and Masking are more common when dataset size is large. This will be evident from the example shared in the next section. Any anomaly detection technique should be robust against swamping and masking\n","\n","b)Change Detection can be defined as the process of identifying differences in the state of an object or phenomenon by observing it at different times "],"metadata":{"id":"kE2qfZdIEToq"}},{"cell_type":"markdown","source":["## 3. What are the steps to follow when building a text classification system?"],"metadata":{"id":"FSsSnvINDD0g"}},{"cell_type":"markdown","source":["Step 1: Gather Data.\n","Step 2: Explore Your Data.\n","Step 2.5: Choose a Model*\n","Step 3: Prepare Your Data.\n","Step 4: Build, Train, and Evaluate Your Model.\n","Step 5: Tune Hyperparameters.\n","Step 6: Deploy Your Mode"],"metadata":{"id":"DPnFleEKakcg"}},{"cell_type":"markdown","source":["## 4. a. What do you mean by a Bag of Words (BOW)?\n","   \n","##   b. What do you mean by Parts of Speech (POS) tagging in NLP?"],"metadata":{"id":"iTzWgQvaDedd"}},{"cell_type":"markdown","source":["a)A bag-of-words is a representation of text that describes the occurrence of words within a document. It involves two things: A vocabulary of known words. A measure of the presence of known words\n","\n","b)What is Part-of-speech (POS) tagging ? It is a process of converting a sentence to forms – list of words, list of tuples (where each tuple is having a form (word, tag)). The tag in case of is a part-of-speech tag, and signifies whether the word is a noun, adjective, verb, and so on"],"metadata":{"id":"k_x1Sr8kaq_o"}},{"cell_type":"markdown","source":["## 5. What is Latent Dirichlet Allocation (LDA) and vector space of LDA ?"],"metadata":{"id":"jyUQuCqtHIdU"}},{"cell_type":"markdown","source":["In natural language processing, Latent Dirichlet Allocation (LDA) refers to a probabilistic generative model for a corpus of documents, when the documents are represented as a combination of the probabilities of belonging to each topic in a Vector Space Model."],"metadata":{"id":"23GtEo__fNYI"}},{"cell_type":"markdown","source":["## 6. How LDA is similar to PCA?"],"metadata":{"id":"FaO9g-IXIhwc"}},{"cell_type":"markdown","source":["Linear discriminant analysis is very similar to PCA both look for linear combinations of the features which best explain the data.\n","\n","The main difference is that the Linear discriminant analysis is a supervised dimensionality reduction technique that also achieves classification of the data simultaneously.\n","\n","LDA focuses on finding a feature subspace that maximizes the separability between the groups.\n","\n","While Principal component analysis is an unsupervised Dimensionality reduction technique, it ignores the class label.\n","\n","PCA focuses on capturing the direction of maximum variation in the data set."],"metadata":{"id":"dJrAwG_ffQ1E"}},{"cell_type":"markdown","source":[],"metadata":{"id":"blwvkweUAsxG"}}]}